{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "taller_recsys.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_ZJgp3JNXVN"
      },
      "source": [
        "# Sistemas de recoemndación\n",
        "\n",
        "En este notebook vamos a famiilarizarnos un poco con algoritmos de sistemas de recomendación y algunas métricas para evaluarlos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fedYtygoMi1g"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from typing import List\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.sparse import coo_matrix\n",
        "from urllib import request"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCo_KsYDOChj"
      },
      "source": [
        "## Lecutra y carga del dataset\n",
        "\n",
        "Lo primero es cargar un dataset, en este caso utilizaremos [movielens](https://grouplens.org/datasets/movielens/100k/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyDkaXCDMpyX"
      },
      "source": [
        "URL = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "ZIP_PATH = \"ml-100k.zip\"\n",
        "CONTENTS_DIR = \"ml-100k\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7VTNv4SOFX9"
      },
      "source": [
        "Las siguientes funciones se encargan de descargar un archivo .zip con los datos, cargar el archivo `\"u.data\"` en un [DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) y convertir esos datos en una matriz de interacciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HWZ-ljRMrmA"
      },
      "source": [
        "def maybe_download(url, fpath):\n",
        "    with open(fpath, \"wb\") as file:\n",
        "        print(\"...downloading to {}\".format(fpath))\n",
        "        response = requests.get(url)\n",
        "        file.write(response.content)\n",
        "    print(\"download complete!\")\n",
        "\n",
        "\n",
        "def zipped_csv_to_df(zip_fpath, csv_fpath, **kwargs):\n",
        "    with zipfile.ZipFile(zip_fpath) as z:\n",
        "        \n",
        "        with z.open(csv_fpath) as f:\n",
        "            df = pd.read_csv(f, **kwargs)\n",
        "\n",
        "    return df\n",
        "\n",
        "def get_items_name(contents_dir, zip_path):\n",
        "    csv_fpath = contents_dir + \"/u.item\"\n",
        "    \n",
        "    names = (\"movie id,movie title,release date,video release date,\"\n",
        "            +\"IMDb URL,unknown,Action,Adventure,Animation,Children's,\"\n",
        "            +\"Comedy,Crime,Documentary,Drama,Fantasy,Film-Noir,Horror,\"\n",
        "            +\"Musical,Mystery,Romance,Sci-Fi,Thriller,War,Western\")\n",
        "            \n",
        "    kwargs = dict(\n",
        "        sep='|', header=None,\n",
        "        names=names.split(','), encoding='latin-1'\n",
        "    )\n",
        "        \n",
        "    df = zipped_csv_to_df(zip_path, csv_fpath, **kwargs)\n",
        "    return df['movie title'].values\n",
        "\n",
        "def convert_ratings_df_to_matrix(\n",
        "        df, shape, columns=\"user id,item id,rating\".split(',')):\n",
        "    data = df[columns].values\n",
        "    users = data[:, 0] - 1 # correct for zero index\n",
        "    items = data[:, 1] - 1 # correct for zero index\n",
        "    values = data[:, 2]\n",
        "    return coo_matrix((values, (users, items)), shape=shape).toarray()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gibq71FJOIVP"
      },
      "source": [
        "Para descargar el dataset solo tenemos que llamar la función de descarga"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7eiMDrwM8Iv",
        "outputId": "25384636-720e-43f8-f316-f3c509e8d038"
      },
      "source": [
        "maybe_download(URL, ZIP_PATH)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...downloading to ml-100k.zip\n",
            "download complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlNUiR_ZOMRX"
      },
      "source": [
        "Luego podemos ver un extracto del dataset que vamos a trabajar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "yZ8jpgi6N2OK",
        "outputId": "747876da-8b24-40b6-db0d-1a738d1f21f1"
      },
      "source": [
        "csv_fpath = CONTENTS_DIR + \"/u.data\"\n",
        "df = zipped_csv_to_df(\n",
        "    ZIP_PATH, csv_fpath, sep='\\t',\n",
        "    header=None, names=\"user id,item id,rating,timestamp\".split(',')\n",
        ")\n",
        "df.head(7)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user id</th>\n",
              "      <th>item id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>298</td>\n",
              "      <td>474</td>\n",
              "      <td>4</td>\n",
              "      <td>884182806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>115</td>\n",
              "      <td>265</td>\n",
              "      <td>2</td>\n",
              "      <td>881171488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user id  item id  rating  timestamp\n",
              "0      196      242       3  881250949\n",
              "1      186      302       3  891717742\n",
              "2       22      377       1  878887116\n",
              "3      244       51       2  880606923\n",
              "4      166      346       1  886397596\n",
              "5      298      474       4  884182806\n",
              "6      115      265       2  881171488"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5-p5ve7ORoq"
      },
      "source": [
        "Podemos ver que el dataset no está dispuesto como una matriz, esto se debe a temas de eficiciencia, ya que al convertirlo en una matriz tendríamos una matriz gigante llena de 0s. Sin embargo, para este ejercicio podrás utilizar la representación que te permita trabajar con mayor comodidad. Si quisieras extraer la matriz gigante, solo tienes que hacer lo siguiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx8AtQKiOkvB",
        "outputId": "31746227-40a6-4a48-8536-ac8894109527"
      },
      "source": [
        "n_users = df['user id'].unique().shape[0]\n",
        "n_items = df['item id'].unique().shape[0]\n",
        "interactions = convert_ratings_df_to_matrix(df, shape=(n_users, n_items)).astype(np.float64)\n",
        "interactions"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5., 3., 4., ..., 0., 0., 0.],\n",
              "       [4., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [5., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 5., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB3ElH21NEmC",
        "outputId": "4258c31a-d4e5-4d46-8cd9-30079a45c55d"
      },
      "source": [
        "items_name = get_items_name(CONTENTS_DIR, ZIP_PATH)\n",
        "items_name"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "       'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "       'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9FDGPTVPEeo"
      },
      "source": [
        "## Evaluación de desempeño\n",
        "\n",
        "Como en todo proceso de aprendizaje supervisado, es importante contar con un set de entrenamiento y otro de validación. A continuación debes implementar la función que lo hace posible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz9zoGzVNNeB"
      },
      "source": [
        "def train_test_split(interactions, k=5, n=2):\n",
        "    \"\"\"Split the interactions matrix.\n",
        "\n",
        "    It is important to remmber that it is not about remmoving rows at\n",
        "    random, because it would remmove the users; instead we want to \n",
        "    remmove some of the interactions of those users with the items.\n",
        "\n",
        "    This function calculates the minimun ratings per user in the \n",
        "    interactions matrix and take it into account to avoid removing \n",
        "    r_ui values for users with less than n*k interactions.\n",
        "\n",
        "    Args:\n",
        "        interactions (np.ndarray): contains the data to be splitted.\n",
        "        k (int): this parameter should be choosen greater than the \n",
        "            precision at k that you want to compute. Think of how many \n",
        "            items you want to recommend for every user. Defaults to 5.\n",
        "        n (int): number of times that a user shuld have interacted with \n",
        "            the items set so that we can move interactions from the \n",
        "            original interactions to the test set.\n",
        "\n",
        "    Returns:\n",
        "        train (np.ndarray): the training set.\n",
        "        test (np.ndarray): the test set.\n",
        "        \n",
        "    \"\"\"\n",
        "    # reserve the rerutn matrices\n",
        "    train = interactions.copy()\n",
        "    test = np.zeros_like(train)\n",
        "\n",
        "    # store all user indices from which we take interactions to the test set\n",
        "    user_test_indices = []\n",
        "\n",
        "    for uid in range(train.shape[0]):\n",
        "        \n",
        "        # get indices (item indices) of the interactions of this user\n",
        "        user_interactions_indices = \n",
        "        \n",
        "        # take k interactions only if that user has more than n*k interactions\n",
        "        if len(user_interactions_indices) >= int(n*k):\n",
        "\n",
        "            # pick k interactions to move to the test set\n",
        "            test_interactions_indices = \n",
        "            \n",
        "            # the train set should be 0 in all places the test set is non zero\n",
        "            train[uid, test_interactions_indices] = \n",
        "\n",
        "            # fill the values of the test set \n",
        "            values = \n",
        "            test[uid, test_interactions_indices] = \n",
        "\n",
        "               \n",
        "    return train, test"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Pid03rP2IV"
      },
      "source": [
        "train, test = train_test_split(interactions)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UGwzXtKP4K7",
        "outputId": "1333b629-b5b3-4894-bc41-793441888936"
      },
      "source": [
        "def msg(name, data):\n",
        "    return f\"{name} data has  shape {data.shape} and {np.sum(data != 0)} interactions\"\n",
        "print(msg(name=\"training\", data=train))\n",
        "print(msg(name=\"test\", data=test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data has  shape (943, 1682) and 95285 interactions\n",
            "test data has  shape (943, 1682) and 4715 interactions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGOZgdsYQpUX"
      },
      "source": [
        "Lo siguiente no debe generar error si la función quedó bien implementada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1J9ev66QUXU"
      },
      "source": [
        "assert np.sum(np.nonzero(train * test)[0]) == 0"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVGMpnrrTHkB"
      },
      "source": [
        "Ahora es tiempo de definir las métricas con las que vamos a trabajar. Realmente solo hace falta implementar las funciones `precision_at_k`  y `recall_at_k`. No es importante cómo lo haces internamente, por lo que puedes ignorar las guías que están comentadas y las funciones que empiezan con la palabra `individual_`; estas están ahí en caso de que las quieras usar como guía."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d33-nRDCQoPz"
      },
      "source": [
        "def individual_precision_at_k(real_scores, pred_scores, k=5, threshold=None):\n",
        "    \"\"\"\n",
        "    Computes the precision at k using the real and predicted scores for\n",
        "    a particular user.\n",
        "\n",
        "    Precision at k is the proportion of recommended items in the top-k\n",
        "    set that are relevant.\n",
        "\n",
        "    Args:\n",
        "        real_scores (np.ndarray): real scores as a\n",
        "            1d array.\n",
        "        pred_scores (np.ndarray): predicted scores as a\n",
        "            1d array.\n",
        "        k (int): compute based on the top k recommendations.\n",
        "        threshold (float): the value of the score from which an item is\n",
        "            considered relevant.\n",
        "\n",
        "    Returns\n",
        "        precision_at_k (float)\n",
        "\n",
        "    \"\"\"\n",
        "    # if a threshold is not provided, asume it is the mean values of the \n",
        "    # real scores\n",
        "    if threshold is None:\n",
        "        threshold = np.mean(real_scores)\n",
        "    \n",
        "    # get the relevant items from the scores use np.where\n",
        "    relevant_items = \n",
        "\n",
        "    # get top k recomendations, use the top k function defined above\n",
        "    recommended_items = \n",
        "    \n",
        "    # find the intersection of the relevant items with the recommended items\n",
        "    recommended_relevant_items = \n",
        "    \n",
        "    # compute the precision at k\n",
        "    precision_at_k = \n",
        "    \n",
        "    return precision_at_k"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KX0UaHBS-0L"
      },
      "source": [
        "def precision_at_k(real_scores, pred_scores, k=5, threshold=None):\n",
        "    \"\"\"Average precistion at k for a list of user indices.\n",
        "    \n",
        "    Args:\n",
        "        real_scores (np.ndarray): real scores as a\n",
        "            2d array of shape (n_users, n_items).\n",
        "        pred_scores (np.ndarray): predicted scores as a\n",
        "            2d array of shape (n_users, n_items).\n",
        "        k (int): compute based on the top k recommendations.\n",
        "        threshold (float): the value of the score from which an item is\n",
        "            considered relevant.\n",
        "    Returns:\n",
        "        average precision at k for the provided or all users (float).\n",
        "\n",
        "    \"\"\"\n",
        "    # if a threshold is not provided, asume it is the mean values of the \n",
        "    # real scores\n",
        "    if threshold is None:\n",
        "        threshold = np.mean(real_scores)\n",
        "        \n",
        "    # initialize the total precision to 0\n",
        "    total_precision = 0\n",
        "    for uid in range(real_scores.shape[0]):\n",
        "        \n",
        "        # take the real scores for this user\n",
        "        user_real_scores = \n",
        "        \n",
        "        # take the predicted scores for this user\n",
        "        user_pred_scores = \n",
        "        \n",
        "        # update total_precision based on the value for this user\n",
        "        total_precision += \n",
        "\n",
        "    # get the average precision\n",
        "    avg_precision = \n",
        "    return avg_precision"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYqbZzGSTMYN"
      },
      "source": [
        "def individual_recall_at_k(real_scores, pred_scores, k=5, threshold=None):\n",
        "    \"\"\"\n",
        "    Computes the precision at k using the real and predicted scores for\n",
        "    a particular user.\n",
        "\n",
        "    Recall at k is the proportion of relevant items found in the top-k\n",
        "    recommendations.\n",
        "\n",
        "    Args:\n",
        "        real_scores (sequence or np.ndarray): real scores as a\n",
        "            1d array.\n",
        "        pred_scores (sequence or np.ndarray): predicted scores as a\n",
        "            1d array.\n",
        "        k (int): compute based on the top k recommendations.\n",
        "        threshold (float): the value of the score from which an item is\n",
        "            considered relevant.\n",
        "\n",
        "    Returns\n",
        "        recall_at_k (float)\n",
        "\n",
        "    \"\"\"\n",
        "    # if a threshold is not provided, asume it is the mean values of the \n",
        "    # real scores\n",
        "    if threshold is None:\n",
        "        threshold = np.mean(real_scores)\n",
        "    \n",
        "    # get the relevant items from the scores use np.where\n",
        "    relevant_items = \n",
        "\n",
        "    # get top k recomendations\n",
        "    recommended_items = \n",
        "    \n",
        "    recommended_relevant_items = \n",
        "\n",
        "    recall_at_k = \n",
        "    return recall_at_k"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIWNBXiWTTGA"
      },
      "source": [
        "def recall_at_k(real_scores, pred_scores, k=5, threshold=None):\n",
        "    \"\"\"Average recall at k for a list of user indices.\n",
        "    \n",
        "    Args:\n",
        "        real_scores (np.ndarray): real scores as a\n",
        "            2d array of shape (n_users, n_items).\n",
        "        pred_scores (sequence or np.ndarray): predicted scores as a\n",
        "            2d array of shape (n_users, n_items).\n",
        "        k (int): compute based on the top k recommendations.\n",
        "        threshold (float): the value of the score from which an item is\n",
        "            considered relevant.\n",
        "    Returns:\n",
        "        average recall at k for the provided or all users (float).\n",
        "\n",
        "    \"\"\"\n",
        "    # if a threshold is not provided, asume it is the mean values of the \n",
        "    # real scores\n",
        "    if threshold is None:\n",
        "        threshold = np.mean(real_scores)\n",
        "        \n",
        "    # initialize the total recall to 0\n",
        "    total_recall = 0\n",
        "    for uid in range(real_scores.shape[0]):\n",
        "        \n",
        "        # take the real scores for this user\n",
        "        user_real_scores = \n",
        "        \n",
        "        # take the predicted scores for this user\n",
        "        user_pred_scores = \n",
        "\n",
        "        # update the toal recall\n",
        "        total_recall += \n",
        "\n",
        "    # compute the average recall\n",
        "    avg_recall = \n",
        "    \n",
        "    return avg_recall"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ML59UXlTjot"
      },
      "source": [
        "## Explorar los resultados que obtenemos con varios métodos\n",
        "\n",
        "### Baseline\n",
        "\n",
        "Lo primero en todo proyecto de Machine Learning es tener un baseline, algo así como un método que sea sencillo y con poco costo computacional. Este método resolverá nuestro problema, aunque los resultados sean muy pobres. La idea es que siempre tengamos un referente para comparar las innovaciones que vamos haciendo en nuestros algoritmos. A este baseline debes calcularle las métricas mencionadas arriba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoPSW73HTToF"
      },
      "source": [
        "raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDzFzff4UXzS"
      },
      "source": [
        "### Método basado en memoria\n",
        "\n",
        "Ahora intenta con un método un poco menos sencillo, utiliza algún método basado en memoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBa5cNKvUfsy"
      },
      "source": [
        "raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2542hfUMUhbX"
      },
      "source": [
        "### Método basado en modelo\n",
        "\n",
        "La idea es agregar complejidad un paso a la vez. Llegó la hora de intentar un método explícito basado en modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U-hHXyzU4oe"
      },
      "source": [
        "raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8uqXgQvU5SZ"
      },
      "source": [
        "### Modelo implícito\n",
        "\n",
        "Recuerda que también existen métodos implícitos, ¿qué tal si nuestro problema se resuelve mejor de esta manera? Llegó la hora de ponerlo a prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD0b8jkcVKMC"
      },
      "source": [
        "raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UroIXEPPVLF6"
      },
      "source": [
        "# Predicciones\n",
        "\n",
        "Dado que ya viste varios modelos en acción, llegó la hora hacer inferencia. Debes implementar la siguiente función"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbaeh7LOWOii"
      },
      "source": [
        "def recommend(user_id: int, k: int = 5) -> List[str]:\n",
        "    \"\"\"\n",
        "    This function takes the id of the user and whatever number of predictions\n",
        "    we want to make for them. Good luck!\n",
        "    \"\"\"\n",
        "    raise NotImplementedError"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ueWRP1WndO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}